{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.5.3\n"
     ]
    }
   ],
   "source": [
    "import platform\n",
    "print (platform.python_version())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" \n",
    "Straightforward table converter to convert Excel tables into ontology files. \n",
    "See the inline documentation in the notebook.\n",
    "\n",
    "7-19-18:\n",
    "1. Start with Chris' i2b2 Hierarchy View\n",
    "2. Last column can optionally be comments\n",
    "3. File is \"*i2b2 Hierarchy View.xslx\"\n",
    "4. By default process all sheets in a file\n",
    "5. There will be a \"ready for i2b2\" folder\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example code to set a keyring password for use below\n",
    "\n",
    "keyring.set_password(password=\"**password_here**\",service_name=\"db.concern_columbia\",username=\"i2b2u\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import and set paths\n",
    "import glob\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import keyring\n",
    "\n",
    "basepath=\"/Users/jeffklann/Dropbox (Partners HealthCare)/CONCERN All Team Work/Data Elements/Data Structures/Ready/For i2b2/\"\n",
    "outpath=\"/Users/jeffklann/Dropbox (Partners HealthCare)/CONCERN All Team Work/Data Elements/Data Structures/Ready/For i2b2/i2b2_output/\"\n",
    "password_columbia = keyring.get_password(service_name='db.concern_columbia',username='i2b2u') # You need to previously have set it with set_password\n",
    "password = keyring.get_password(service_name='db.concern_phs',username='concern_user') # You need to previously have set it with set_password"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * mssql+pymssql://concern_user:***@phssql2193.partners.org/CONCERN_DEV?charset=utf8\n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "# Connect to SQL for persistence\n",
    "%load_ext sql\n",
    "connect = \"mssql+pymssql://concern_user:%s@phssql2193.partners.org/CONCERN_DEV?charset=utf8\" % password\n",
    "#connect = \"mssql+pymssql://i2b2u:%s@10.171.30.160/CONCERN_DEV?charset=utf8\" % password_columbia\n",
    "%sql $connect\n",
    "%sql USE CONCERN_DEV\n",
    "\n",
    "import sqlalchemy\n",
    "engine = sqlalchemy.create_engine(connect)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sqlalchemy.engine.result.ResultProxy at 0x1122b9ba8>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# (Re)create the target ontology table\n",
    "sql = \"\"\"\n",
    "CREATE TABLE [dbo].[autoprocessed_i2b2ontology]  ( \n",
    "    [index]                 int NOT NULL,\n",
    "\t[C_HLEVEL]          \tint NOT NULL,\n",
    "\t[C_FULLNAME]        \tvarchar(4000) NOT NULL,\n",
    "\t[C_NAME]            \tvarchar(2000) NOT NULL,\n",
    "\t[C_SYNONYM_CD]      \tchar(1) NOT NULL,\n",
    "\t[C_VISUALATTRIBUTES]\tchar(3) NOT NULL,\n",
    "\t[C_TOTALNUM]        \tint NULL,\n",
    "\t[C_BASECODE]        \tvarchar(250) NULL,\n",
    "\t[C_METADATAXML]     \tvarchar(max) NULL,\n",
    "\t[C_FACTTABLECOLUMN] \tvarchar(50) NOT NULL,\n",
    "\t[C_TABLENAME]       \tvarchar(50) NOT NULL,\n",
    "\t[C_COLUMNNAME]      \tvarchar(50) NOT NULL,\n",
    "\t[C_COLUMNDATATYPE]  \tvarchar(50) NOT NULL,\n",
    "\t[C_OPERATOR]        \tvarchar(10) NOT NULL,\n",
    "\t[C_DIMCODE]         \tvarchar(700) NOT NULL,\n",
    "\t[C_COMMENT]         \tvarchar(max) NULL,\n",
    "\t[C_TOOLTIP]         \tvarchar(900) NULL,\n",
    "\t[M_APPLIED_PATH]    \tvarchar(700) NOT NULL,\n",
    "\t[UPDATE_DATE]       \tdatetime NULL,\n",
    "\t[DOWNLOAD_DATE]     \tdatetime NULL,\n",
    "\t[IMPORT_DATE]       \tdatetime NULL,\n",
    "\t[SOURCESYSTEM_CD]   \tvarchar(50) NULL,\n",
    "\t[VALUETYPE_CD]      \tvarchar(50) NULL,\n",
    "\t[M_EXCLUSION_CD]    \tvarchar(25) NULL,\n",
    "\t[C_PATH]            \tvarchar(300) NULL,\n",
    "\t[C_SYMBOL]          \tvarchar(100) NULL \n",
    "\t)\n",
    "ON [PRIMARY]\n",
    "\tTEXTIMAGE_ON [PRIMARY]\n",
    "\tWITH (\n",
    "\t\tDATA_COMPRESSION = NONE\n",
    "\t)\n",
    "\"\"\"\n",
    "engine.execute(\"drop table autoprocessed_i2b2ontology\")\n",
    "engine.execute(sql)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\" Input a df with columns (minimally): Name, Code, [Ancestor_Code]*, [Modifier]\n",
    "     If Modifier column is included, the legal values are \"\" or \"Y\"\n",
    "     Will add additional columns: tooltip, h_level, fullname \n",
    "     rootName is prepended to the path for non-modifiers\n",
    "     rootModName is prepended to the path for modifiers\n",
    "     \n",
    "     Derived from ontology_gen_flowsheet.py\n",
    "     \"\"\"\n",
    "def OntProcess(rootName, df,rootModName='MOD'):\n",
    "    # Little inner function that renames the fullname (replaces rootName with rootName+'_MOD') if modifier is 'Y'\n",
    "    def fullmod(fullname,modifier):\n",
    "        ret=fullname.replace('\\\\'+rootName,'\\\\'+rootModName) if modifier=='Y' else fullname\n",
    "        return ret\n",
    "    \n",
    "    ancestors=[1,-6] if 'Modifier' in df.columns else [1,-5]\n",
    "    df['fullname']=''\n",
    "    df['tooltip']=''\n",
    "    df['path']=''\n",
    "    df['h_level']=np.nan\n",
    "    df['has_children']=0\n",
    "    df=doNonrecursive(df,ancestors)\n",
    "    df['fullname']=df['fullname'].map(lambda x: x.lstrip(':\\\\')).map(lambda x: x.rstrip(':\\\\'))\n",
    "    df['fullname']='\\\\'+rootName+'\\\\'+df['fullname'].map(str)+\"\\\\\"\n",
    "    df['h_level']=df['fullname'].str.count('\\\\\\\\')-2\n",
    "    if ('Modifier' in df.columns): \n",
    "        # If modifier subtract 1 from hlevel and change the root to root+'_MOD'\n",
    "        df['h_level']=df['h_level']-df['Modifier'].fillna('').str.len()\n",
    "        df['fullname']=df[['fullname','Modifier']].apply(lambda x: fullmod(*x), axis=1) #sjm on stackoverflow\n",
    "    \n",
    "    # Parent check! Will report has_children is true if the Code in each row is ever used as a parent code\n",
    "    if (len(df.columns)>7):\n",
    "        mydf = df\n",
    "        mymerge = mydf.merge(mydf,left_on=mydf.columns[1],right_on=mydf.columns[2],how='inner',suffixes=['','_r']).groupby('Code').size().reset_index().rename(lambda x: 'size' if x==0 else x,axis='columns')\n",
    "        mymerge=mydf.merge(mymerge,\n",
    "                     left_on='Code',right_on='Code',how='left')\n",
    "        df['has_children'] = (mymerge['size'] > 0)\n",
    "    else:\n",
    "        df['has_children'] = False\n",
    "        \n",
    "    #old bad code\n",
    "    #df['has_children'] = df['h_level']-len(df.columns[1:-5])-2 - This old version just checked to see if this element was at the max depth, which tells us nothing!\n",
    "    #df['has_children'] = df['has_children'].replace({-1:'Y',0:'N'})\n",
    "    #df['Code'].join(df.ix(3))\n",
    "\n",
    "    df=df.append({'fullname':'\\\\'+rootName+'\\\\','Name':rootName.replace('\\\\',' '),'Code':'toplevel|'+rootName.replace('\\\\',' '),'h_level':1,'has_children':True},ignore_index=True) # Add root node\n",
    "    \n",
    "    return df\n",
    "\n",
    "def doNonrecursive(df,ancestors):\n",
    "    cols=df.columns[ancestors[0]:ancestors[1]][::-1] # Go from column 5 before the end (we added a bunch of columns) backward to first column\n",
    "    print(cols)\n",
    "    for col in cols:\n",
    "        # doesn't work - mycol = df[col].to_string(na_rep='')\n",
    "        mycol = df[col].apply(lambda x: x if isinstance(x, str) else \"{:.0f}\".format(x)).astype('str').replace('nan','')\n",
    "        df.fullname = df.fullname.str.cat(mycol,sep='\\\\',na_rep='')\n",
    "    return df\n",
    "\n",
    "\"\"\" Input a df with (minimally): Name, Code, [Ancestor_Code]*, [Modifier], fullname, path, h_level\n",
    "    Optionally input an applied path for modifiers (only one is supported per ontology at present)\n",
    "       Outputs an i2b2 ontology compatible df. \n",
    "        \"\"\"\n",
    "def OntBuild(df,appliedName=''):\n",
    "    odf = pd.DataFrame()\n",
    "    odf['c_hlevel']=df['h_level']\n",
    "    odf['c_fullname']=df['fullname']\n",
    "    odf['c_visualattributes']=df['has_children'].apply(lambda x: 'FAE' if x==True else 'LAE')\n",
    "    odf['m_applied_path']='@'\n",
    "    if 'Modifier' in df.columns:\n",
    "        odf['c_visualattributes']=odf['c_visualattributes']+df.Modifier.fillna('')\n",
    "        odf['c_visualattributes'].replace(to_replace={'FAEY':'OAE','LAEY':'RAE'},inplace=True)\n",
    "        odf['m_applied_path']=df.Modifier.apply(lambda x: '\\\\'+appliedName+'\\\\%' if x=='Y' else '@')\n",
    "    odf['c_name']=df['Name']\n",
    "    odf['c_path']=df['path']\n",
    "    odf['c_basecode']=df['Code'] # Assume here leafs are unique, not dependent on parent code (unlike flowsheets)\n",
    "    odf['c_symbol']=odf['c_basecode']\n",
    "    odf['c_synonym_cd']='N'\n",
    "    odf['c_facttablecolumn']='concept_cd'\n",
    "    odf['c_tablename']='concept_dimension'\n",
    "    odf['c_columnname']='concept_path'\n",
    "    odf['c_columndatatype']='T' #this is not the tval/nval switch - 2/20/18 - df['vtype'].apply(lambda x: 'T' if x==2 else 'N')\n",
    "    odf['c_totalnum']=''\n",
    "    odf['c_operator']='LIKE'\n",
    "    odf['c_dimcode']=df['fullname']\n",
    "    odf['c_comment']=None\n",
    "    odf['c_tooltip']=df['fullname'] # Tooltip right now is just the fullname again\n",
    "    #odf['c_metadataxml']=df[['vtype','Label']].apply(lambda x: mdx.genXML(mdx.mapper(x[0]),x[1]),axis=1)\n",
    "    return odf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---ADT Event_0\n",
      "Index(['Name', 'Code', 'Parent', 'Grandparent', 'Great-grandparent'], dtype='object')\n",
      "Index(['Great-grandparent', 'Grandparent', 'Parent', 'Code'], dtype='object')\n",
      "---ADT Event_1\n",
      "Index(['Name', 'Code', 'Parent'], dtype='object')\n",
      "Index(['Parent', 'Code'], dtype='object')\n",
      "---Clinician\n",
      "Index(['Name', 'Code', 'Parent'], dtype='object')\n",
      "Index(['Parent', 'Code'], dtype='object')\n",
      "---MAR\n",
      "Index(['Name', 'Code', 'Parent', 'Grandparent', 'Modifier'], dtype='object')\n",
      "Index(['Grandparent', 'Parent', 'Code'], dtype='object')\n",
      "---Outcome Rapid Response and Cardiopulmonary Arrest\n",
      "Index(['Name', 'Code', 'Parent', 'Grandparent'], dtype='object')\n",
      "Index(['Grandparent', 'Parent', 'Code'], dtype='object')\n",
      "---Outcome Readmission\n",
      "Index(['Name', 'Code', 'Parent'], dtype='object')\n",
      "Index(['Parent', 'Code'], dtype='object')\n",
      "---Outcome Sepsis\n",
      "Index(['Name', 'Code'], dtype='object')\n",
      "Index(['Code'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Main loop to process all files in a directory, export to csv, and upload the concatenated version to a database\n",
    "dfs = []\n",
    "for f in glob.iglob(basepath+\"*.xlsx\"): # the old place, multi-directory - now all in one dir\"**/*i2b2 Hierarchy View*.xlsx\"):\n",
    "    if ('~$' in f): continue # Work around Mac temp files\n",
    "    dfd = pd.read_excel(f,sheet_name=None)\n",
    "    for i,s in enumerate(dfd.keys()): # Now take all sheets, not just 'Sheet1'\n",
    "        df=dfd[s].dropna(axis='columns',how='all')\n",
    "        if len(df.columns)>1:\n",
    "            # Prettyprint the root node name from file and sheet name\n",
    "            shortf = f[f.rfind('/')+1:] # Remove path, get file name only\n",
    "            shortf = shortf[:shortf.find(\"i2b2\")].strip(' ') # Stop at 'i2b2', bc files should be named *i2b2 hierarchy view.xlsx\n",
    "            shortf=shortf+('' if s=='Sheet1' else '_'+str(i))\n",
    "            print('---'+shortf)\n",
    "            \n",
    "            # Clean up df\n",
    "            df = df.rename(columns={'Code (concept_CD/inpatient note type CD)':'Code'}) # Hack bc one file has wrong col name\n",
    "            df = df.drop(['Definition','definition','Comment','Comments'],axis=1,errors='ignore') # Drop occasional definition and comment columns\n",
    "            print(df.columns)\n",
    "            \n",
    "            # Process df and add to superframe (dfs)\n",
    "            df = OntProcess('CONCERN\\\\'+shortf,df,'CONCERN_MOD\\\\'+shortf)\n",
    "            ndf = OntBuild(df,'CONCERN\\\\'+shortf).fillna('None')\n",
    "            dfs.append(ndf)\n",
    "            #ndf.to_csv(outpath+shortf+s+\"_autoprocessed.csv\")\n",
    "outdf = pd.concat(dfs)\n",
    "outdf = outdf.append({'c_hlevel':0,'c_fullname':'\\\\CONCERN\\\\','c_name':'CONCERN Root','c_basecode':'.dummy','c_visualattributes':'CAE','c_synonym_cd':'N','c_facttablecolumn':'concept_cd','c_tablename':'concept_dimension','c_columnname':'concept_path','c_columndatatype':'T','c_operator':'LIKE','c_dimcode':'\\\\CONCERN\\\\','m_applied_path':'@'},ignore_index=True)\n",
    "outdf.to_csv(outpath+\"autoprocessed_i2b2ontology.csv\")\n",
    "engine.execute(\"delete from autoprocessed_i2b2ontology\") # if we use SQLMagic in the same cell as SQLAlchemy, it seems to hang\n",
    "outdf.to_sql('autoprocessed_i2b2ontology',con=engine,if_exists='append')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: codes used multiple times, check to verify this is intentional:\n",
      "c_basecode\n",
      "RR_CPR_EVENT_COMBINED    2\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Perform check to make sure no codes are used twice. This is not necessarily an error so only output a warning.\n",
    "dups = outdf.groupby('c_basecode').size()\n",
    "dups = dups[dups>1]\n",
    "if len(dups)>0:\n",
    "    print(\"Warning: codes used multiple times, check to verify this is intentional:\")\n",
    "    print(dups)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "# End of main code...\n",
    "------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Special hacked code for the weird ADT table file format\n",
    "# DEPRECATED\n",
    "dfs = []\n",
    "dfd=pd.read_excel(basepath+\"ADT/ADTEventHierarchy AND LocationHierarchy for Each site i2b2 June 21 2018_update.xlsx\",\n",
    "                  sheet_name=None)\n",
    "for k,v in dfd.items():\n",
    "    shortf=k[0:k.find(' ',k.find(' ')+1)].replace(' ','_')\n",
    "    print(shortf)\n",
    "    df=v.dropna(axis='columns',how='all')\n",
    "    df = df.drop(['C_TOOLTIP','c_tooltip'],axis=1,errors='ignore')\n",
    "    print(df.columns)\n",
    "    df = OntProcess('CONCERN\\\\'+shortf,df)\n",
    "    ndf = OntBuild(df)\n",
    "    dfs.append(ndf)\n",
    "    ndf.to_csv(outpath+shortf+\"_autoprocessed.csv\")\n",
    "#tname = 'out_'+shortf\n",
    "#globals()[tname]=ndf\n",
    "#%sql DROP TABLE $tname\n",
    "#%sql PERSIST $tname"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "# Example of persisting table with SQL Magic\n",
    "testdict={\"animal\":[\"dog\",'cat'],'size':[30,15]}\n",
    "zoop = pd.DataFrame(testdict)\n",
    "tname = 'zoop'\n",
    "%sql DROP TABLE $tname\n",
    "%sql PERSIST $tname"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%sql SELECT * from autoprocessed_i2b2ontology\n",
    "#engine.execute(\"SELECT * FROM autoprocessed_i2b2ontology\").fetchall()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Workspace, working on folder check code\n",
    "mydf = dfs[0]\n",
    "\n",
    "mymerge = mydf.merge(mydf,left_on=mydf.columns[3],right_on=mydf.columns[4],how='inner',suffixes=['','_r']).groupby('c_fullname').size().reset_index().rename(lambda x: 'size' if x==0 else x,axis='columns')\n",
    "mymerge=mydf.merge(mymerge,\n",
    "                 left_on='c_fullname',right_on='c_fullname',how='left')\n",
    "print(mymerge['size'] > 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
